# This file was automatically generated by gh-aw. DO NOT EDIT.
# To update this file, edit the corresponding .md file and run:
#   gh aw compile

name: "Secure Web Research Task"
on:
  pull_request:
    branches:
    - main
  workflow_dispatch: null

permissions: {}

concurrency:
  group: "gh-aw-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}"
  cancel-in-progress: true

run-name: "Secure Web Research Task"

jobs:
  secure-web-research-task:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
      - name: Generate Network Permissions Hook
        run: |
          mkdir -p .claude/hooks
          cat > .claude/hooks/network_permissions.py << 'EOF'
          #!/usr/bin/env python3
          """
          Network permissions validator for Claude Code engine.
          Generated by gh-aw from engine network permissions configuration.
          """
          
          import json
          import sys
          import urllib.parse
          import re
          
          # Domain whitelist (populated during generation)
          ALLOWED_DOMAINS = ["docs.github.com"]
          
          def extract_domain(url_or_query):
              """Extract domain from URL or search query."""
              if not url_or_query:
                  return None
              
              if url_or_query.startswith(('http://', 'https://')):
                  return urllib.parse.urlparse(url_or_query).netloc.lower()
              
              # Check for domain patterns in search queries
              match = re.search(r'site:([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', url_or_query)
              if match:
                  return match.group(1).lower()
              
              return None
          
          def is_domain_allowed(domain):
              """Check if domain is allowed."""
              if not domain:
                  # If no domain detected, allow only if not under deny-all policy
                  return bool(ALLOWED_DOMAINS)  # False if empty list (deny-all), True if has domains
              
              # Empty allowed domains means deny all
              if not ALLOWED_DOMAINS:
                  return False
              
              for pattern in ALLOWED_DOMAINS:
                  regex = pattern.replace('.', r'\.').replace('*', '.*')
                  if re.match(f'^{regex}$', domain):
                      return True
              return False
          
          # Main logic
          try:
              data = json.load(sys.stdin)
              tool_name = data.get('tool_name', '')
              tool_input = data.get('tool_input', {})
              
              if tool_name not in ['WebFetch', 'WebSearch']:
                  sys.exit(0)  # Allow other tools
              
              target = tool_input.get('url') or tool_input.get('query', '')
              domain = extract_domain(target)
              
              # For WebSearch, apply domain restrictions consistently
              # If no domain detected in search query, check if restrictions are in place
              if tool_name == 'WebSearch' and not domain:
                  # Since this hook is only generated when network permissions are configured,
                  # empty ALLOWED_DOMAINS means deny-all policy
                  if not ALLOWED_DOMAINS:  # Empty list means deny all
                      print(f"Network access blocked: deny-all policy in effect", file=sys.stderr)
                      print(f"No domains are allowed for WebSearch", file=sys.stderr)
                      sys.exit(2)  # Block under deny-all policy
                  else:
                      print(f"Network access blocked for WebSearch: no specific domain detected", file=sys.stderr)
                      print(f"Allowed domains: {', '.join(ALLOWED_DOMAINS)}", file=sys.stderr)
                      sys.exit(2)  # Block general searches when domain allowlist is configured
              
              if not is_domain_allowed(domain):
                  print(f"Network access blocked for domain: {domain}", file=sys.stderr)
                  print(f"Allowed domains: {', '.join(ALLOWED_DOMAINS)}", file=sys.stderr)
                  sys.exit(2)  # Block with feedback to Claude
              
              sys.exit(0)  # Allow
              
          except Exception as e:
              print(f"Network validation error: {e}", file=sys.stderr)
              sys.exit(2)  # Block on errors
          
          EOF
          chmod +x .claude/hooks/network_permissions.py
      - name: Generate Claude Settings
        run: |
          cat > .claude/settings.json << 'EOF'
          {
            "hooks": {
              "PreToolUse": [
                {
                  "matcher": "WebFetch|WebSearch",
                  "hooks": [
                    {
                      "type": "command",
                      "command": ".claude/hooks/network_permissions.py"
                    }
                  ]
                }
              ]
            }
          }
          EOF
      - name: Setup MCPs
        run: |
          mkdir -p /tmp/mcp-config
          cat > /tmp/mcp-config/mcp-servers.json << 'EOF'
          {
            "mcpServers": {
              "github": {
                "command": "docker",
                "args": [
                  "run",
                  "-i",
                  "--rm",
                  "-e",
                  "GITHUB_PERSONAL_ACCESS_TOKEN",
                  "ghcr.io/github/github-mcp-server:sha-45e90ae"
                ],
                "env": {
                  "GITHUB_PERSONAL_ACCESS_TOKEN": "${{ secrets.GITHUB_TOKEN }}"
                }
              }
            }
          }
          EOF
      - name: Create prompt
        run: |
          mkdir -p /tmp/aw-prompts
          cat > /tmp/aw-prompts/prompt.txt << 'EOF'
          # Secure Web Research Task
          
          Please research the GitHub API documentation or Stack Overflow and find information about repository topics. Summarize them in a brief report.
          
          EOF
      - name: Print prompt to step summary
        run: |
          echo "## Generated Prompt" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '``````markdown' >> $GITHUB_STEP_SUMMARY
          cat /tmp/aw-prompts/prompt.txt >> $GITHUB_STEP_SUMMARY
          echo '``````' >> $GITHUB_STEP_SUMMARY
      - name: Generate agentic run info
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            const awInfo = {
              engine_id: "claude",
              engine_name: "Claude Code",
              model: "",
              version: "",
              workflow_name: "Secure Web Research Task",
              experimental: false,
              supports_tools_whitelist: true,
              supports_http_transport: true,
              run_id: context.runId,
              run_number: context.runNumber,
              run_attempt: process.env.GITHUB_RUN_ATTEMPT,
              repository: context.repo.owner + '/' + context.repo.repo,
              ref: context.ref,
              sha: context.sha,
              actor: context.actor,
              event_name: context.eventName,
              created_at: new Date().toISOString()
            };
            
            // Write to /tmp directory to avoid inclusion in PR
            const tmpPath = '/tmp/aw_info.json';
            fs.writeFileSync(tmpPath, JSON.stringify(awInfo, null, 2));
            console.log('Generated aw_info.json at:', tmpPath);
            console.log(JSON.stringify(awInfo, null, 2));
      - name: Upload agentic run info
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: aw_info.json
          path: /tmp/aw_info.json
          if-no-files-found: warn
      - name: Execute Claude Code Action
        id: agentic_execution
        uses: anthropics/claude-code-base-action@v0.0.56
        with:
          # Allowed tools (sorted):
          # - Glob
          # - Grep
          # - LS
          # - NotebookRead
          # - Read
          # - Task
          # - WebFetch
          # - WebSearch
          # - mcp__github__download_workflow_run_artifact
          # - mcp__github__get_code_scanning_alert
          # - mcp__github__get_commit
          # - mcp__github__get_dependabot_alert
          # - mcp__github__get_discussion
          # - mcp__github__get_discussion_comments
          # - mcp__github__get_file_contents
          # - mcp__github__get_issue
          # - mcp__github__get_issue_comments
          # - mcp__github__get_job_logs
          # - mcp__github__get_me
          # - mcp__github__get_notification_details
          # - mcp__github__get_pull_request
          # - mcp__github__get_pull_request_comments
          # - mcp__github__get_pull_request_diff
          # - mcp__github__get_pull_request_files
          # - mcp__github__get_pull_request_reviews
          # - mcp__github__get_pull_request_status
          # - mcp__github__get_secret_scanning_alert
          # - mcp__github__get_tag
          # - mcp__github__get_workflow_run
          # - mcp__github__get_workflow_run_logs
          # - mcp__github__get_workflow_run_usage
          # - mcp__github__list_branches
          # - mcp__github__list_code_scanning_alerts
          # - mcp__github__list_commits
          # - mcp__github__list_dependabot_alerts
          # - mcp__github__list_discussion_categories
          # - mcp__github__list_discussions
          # - mcp__github__list_issues
          # - mcp__github__list_notifications
          # - mcp__github__list_pull_requests
          # - mcp__github__list_secret_scanning_alerts
          # - mcp__github__list_tags
          # - mcp__github__list_workflow_jobs
          # - mcp__github__list_workflow_run_artifacts
          # - mcp__github__list_workflow_runs
          # - mcp__github__list_workflows
          # - mcp__github__search_code
          # - mcp__github__search_issues
          # - mcp__github__search_orgs
          # - mcp__github__search_pull_requests
          # - mcp__github__search_repositories
          # - mcp__github__search_users
          allowed_tools: "Glob,Grep,LS,NotebookRead,Read,Task,WebFetch,WebSearch,mcp__github__download_workflow_run_artifact,mcp__github__get_code_scanning_alert,mcp__github__get_commit,mcp__github__get_dependabot_alert,mcp__github__get_discussion,mcp__github__get_discussion_comments,mcp__github__get_file_contents,mcp__github__get_issue,mcp__github__get_issue_comments,mcp__github__get_job_logs,mcp__github__get_me,mcp__github__get_notification_details,mcp__github__get_pull_request,mcp__github__get_pull_request_comments,mcp__github__get_pull_request_diff,mcp__github__get_pull_request_files,mcp__github__get_pull_request_reviews,mcp__github__get_pull_request_status,mcp__github__get_secret_scanning_alert,mcp__github__get_tag,mcp__github__get_workflow_run,mcp__github__get_workflow_run_logs,mcp__github__get_workflow_run_usage,mcp__github__list_branches,mcp__github__list_code_scanning_alerts,mcp__github__list_commits,mcp__github__list_dependabot_alerts,mcp__github__list_discussion_categories,mcp__github__list_discussions,mcp__github__list_issues,mcp__github__list_notifications,mcp__github__list_pull_requests,mcp__github__list_secret_scanning_alerts,mcp__github__list_tags,mcp__github__list_workflow_jobs,mcp__github__list_workflow_run_artifacts,mcp__github__list_workflow_runs,mcp__github__list_workflows,mcp__github__search_code,mcp__github__search_issues,mcp__github__search_orgs,mcp__github__search_pull_requests,mcp__github__search_repositories,mcp__github__search_users"
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          claude_env: |
            GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          mcp_config: /tmp/mcp-config/mcp-servers.json
          prompt_file: /tmp/aw-prompts/prompt.txt
          settings: .claude/settings.json
          timeout_minutes: 5
      - name: Capture Agentic Action logs
        if: always()
        run: |
          # Copy the detailed execution file from Agentic Action if available
          if [ -n "${{ steps.agentic_execution.outputs.execution_file }}" ] && [ -f "${{ steps.agentic_execution.outputs.execution_file }}" ]; then
            cp ${{ steps.agentic_execution.outputs.execution_file }} /tmp/secure-web-research-task.log
          else
            echo "No execution file output found from Agentic Action" >> /tmp/secure-web-research-task.log
          fi
          
          # Ensure log file exists
          touch /tmp/secure-web-research-task.log
      - name: Check if workflow-complete.txt exists, if so upload it
        id: check_file
        run: |
          if [ -f workflow-complete.txt ]; then
            echo "File exists"
            echo "upload=true" >> $GITHUB_OUTPUT
          else
            echo "File does not exist"
            echo "upload=false" >> $GITHUB_OUTPUT
          fi
      - name: Upload workflow-complete.txt
        if: steps.check_file.outputs.upload == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: workflow-complete
          path: workflow-complete.txt
      - name: Upload engine output files
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: agent_outputs
          path: |
            output.txt
          if-no-files-found: ignore
      - name: Upload agent logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: secure-web-research-task.log
          path: /tmp/secure-web-research-task.log
          if-no-files-found: warn

